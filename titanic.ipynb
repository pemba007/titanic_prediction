{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "orig_nbformat": 4,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.6 64-bit ('base': conda)"
    },
    "interpreter": {
      "hash": "da68a583c375f369d93b959c6591ee7513b9823a019fdc8632dfe20068c45b74"
    },
    "colab": {
      "name": "titanic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "96qNZTHU0Tgb"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0EIQrLZ0Tge"
      },
      "source": [
        "# Define Function for removing column\n",
        "\n",
        "def remove_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    return df.drop(['PassengerId','Cabin','Ticket','Name'],axis = 1)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBOMUbor0Tge"
      },
      "source": [
        "# Testing Function For Name Features\n",
        "def preprocessName(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df['Last Name'] = df.apply(lambda row: row[\"Name\"][:row[\"Name\"].find(',')], axis = 1)\n",
        "    df['Title'] = df.apply(lambda row: row[\"Name\"][row[\"Name\"].find(',')+2:row[\"Name\"].find('.')], axis=1)\n",
        "    return df "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sn2wufyt0Tgf",
        "outputId": "76bebfe0-31fc-4862-c9dd-a36597f85883"
      },
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "df_test = pd.read_csv('test.csv')\n",
        "print(type(df))\n",
        "print(type(df_test))\n",
        "output_Id = df_test['PassengerId']"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n<class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PassengerId      int64\nSurvived         int64\nPclass           int64\nName            object\nSex             object\nAge            float64\nSibSp            int64\nParch            int64\nTicket          object\nFare           float64\nCabin           object\nEmbarked        object\ndtype: object\n"
          ]
        }
      ],
      "source": [
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name        False\nSex         False\nTicket      False\nCabin        True\nEmbarked     True\ndtype: bool\n"
          ]
        }
      ],
      "source": [
        "print(df.select_dtypes(\"object\").isna().sum() > 0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGEx3tVP0Tgg"
      },
      "source": [
        "# Transformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "\n",
        "# df = remove_columns(df)\n",
        "# df_test = remove_columns(df_test)\n",
        "\n",
        "# X_columns = ['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
        "# Y_columns = ['Survived']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.drop([\"Survived\"], axis = 1), df[\"Survived\"], test_size=.33,random_state=10)\n",
        "\n",
        "X_train = preprocessName(X_train)\n",
        "X_test = preprocessName(X_test)\n",
        "\n",
        "# Scale numeric values\n",
        "\n",
        "num_features = ['Age','SibSp','Parch','Fare']\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "# Transformer for Embarked\n",
        "embarked_transformer = Pipeline(steps=[('imputing', SimpleImputer(strategy='most_frequent')),('encoding', OneHotEncoder())])\n",
        "\n",
        "# Categorical encoding\n",
        "categorical_features = ['Sex', 'Pclass', 'Title', 'Last Name', 'Ticket']\n",
        "\n",
        "# Name\n",
        "\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[('embark', embarked_transformer, ['Embarked']), ('num_transform', num_transformer, num_features),('cat_transformer', OneHotEncoder(handle_unknown='ignore'), categorical_features)],remainder='drop')\n",
        "\n",
        "pipe = Pipeline(steps=[('preprocessor', preprocessor)])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "hjZ0HpBB0Tgh"
      },
      "source": [
        "# pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "# np.set_printoptions(precision=4, threshold = sys.maxsize)\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "X_train = pipe.transform(X_train)\n",
        "X_test = pipe.transform(X_test)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2CIVBiO0Tgi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "195bb512-e9c0-4f11-abfe-df123f4630cc"
      },
      "source": [
        "# Predict \n",
        "print(type(X_train))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse.csr.csr_matrix'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIUS39bB0Tgj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5884868c-f238-4765-8fa7-d4b251f569b9"
      },
      "source": [
        "# Classification\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score,make_scorer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Trying multiple models\n",
        "\n",
        "# Additional Imports\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "\n",
        "clf = MLPClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"Accuracy for MPC CLassifier\", accuracy_score(y_test, clf.predict(X_test)))\n",
        "\n",
        "clf = SVC()\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"Accuracy for SVC\", accuracy_score(y_test, clf.predict(X_test)))\n",
        "\n",
        "clf = AdaBoostClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"Accuracy for AdaBoostClassifier\", accuracy_score(y_test, clf.predict(X_test)))\n",
        "\n",
        "clf = KNeighborsClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"Accuracy for KNeighborsClassifier\", accuracy_score(y_test, clf.predict(X_test)))\n",
        "\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"Accuracy for DecisionTreeClassifier\", accuracy_score(y_test, clf.predict(X_test)))\n",
        "\n",
        "# clf = GaussianProcessClassifier()\n",
        "# clf.fit(X_train, y_train)\n",
        "# print(\"Accuracy for GaussianProcessClassifier\", accuracy_score(y_test, clf.predict(X_test)))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for MPC CLassifier 0.8372881355932204\n",
            "Accuracy for SVC 0.8338983050847457\n",
            "Accuracy for AdaBoostClassifier 0.8338983050847457\n",
            "Accuracy for KNeighborsClassifier 0.8372881355932204\n",
            "Accuracy for DecisionTreeClassifier 0.8067796610169492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TczwR-WKRUZC",
        "outputId": "e3465bb8-13aa-4658-8a06-53f337ef6974"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0).fit(X_train, y_train)\n",
        "\n",
        "print(accuracy_score(y_test, clf.predict(X_test)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8440677966101695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzBLE1Er0Tgj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5b5a958-fa74-43c7-9c44-3b8c5056f3dc"
      },
      "source": [
        "# scorer = make_scorer(accuracy_score)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "n_estimators = [100, 300, 500, 800, 1200]\n",
        "learning_rate = [0.01, 0.1, 0.2, 0.5]\n",
        "max_depth = [1, 5, 8, 15, 25, 30]\n",
        "min_samples_split = [2, 5, 10, 15, 100]\n",
        "min_samples_leaf = [1, 2, 5, 10] \n",
        "# kernel = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
        "# degree = [1,2,3,4,5,6,7,8,9]\n",
        "\n",
        "model = GradientBoostingClassifier(random_state=0)\n",
        "\n",
        "hyperF = dict(n_estimators = n_estimators, learning_rate = learning_rate, max_depth = max_depth, min_samples_split = min_samples_split, min_samples_leaf=min_samples_leaf)\n",
        "\n",
        "# clf = GridSearchCV(model, hyperF, verbose = 1, n_jobs = -1, refit='Accuracy', scoring = {'Accuracy': make_scorer(accuracy_score)})\n",
        "\n",
        "# clf = RandomForestClassifier(max_depth= 25, min_samples_leaf = 1, min_samples_split = 10, n_estimators= 300,  n_jobs = -1)\n",
        "# clf.fit(X_train, y_train)\n",
        "# print(accuracy_score(y_test, clf.predict(X_test)))\n",
        "\n",
        "# print(clf.best_params_)\n",
        "# print(clf.cv_results_)\n",
        "\n",
        "# bestF = gridF.fit(x_train, y_train)\n",
        "\n",
        "# values = np.arange(10,30,1)\n",
        "\n",
        "# arr = []\n",
        "\n",
        "# for x in values:\n",
        "#     clf = RandomForestClassifier(max_depth=5, random_state=0, n_estimators = 11, n_jobs = -1, verbose = 1)\n",
        "#     clf.fit(X_train,y_train)\n",
        "#     accuracy = accuracy_score(y_test, clf.predict(X_test))\n",
        "    \n",
        "#     arr.append(accuracy)\n",
        "\n",
        "# plt.plot(values, np.array(arr))\n",
        "# plt.title('Graph')\n",
        "# plt.xlabel('Max Depth')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.show()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaL2Rq_q0Tgk"
      },
      "source": [
        "# Training With Complete Train Data\n",
        "# 'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 300\n",
        "# df_Y = df[\"Survived\"]\n",
        "# df_X = df.drop([\"Survived\"], axis = 1)\n",
        "# df_X = pipe.fit_transform(df_X, df_Y)\n",
        "# clf.fit(df_X, df_Y)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUwM_wi50Tgl"
      },
      "source": [
        "# print(clf.best_params_)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4kTL58X0Tgl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7678f950-a032-4180-debe-2ab20750d388"
      },
      "source": [
        "# Predicting\n",
        "# clf = RandomForestClassifier(max_depth= 25, min_samples_leaf = 1, min_samples_split = 10, n_estimators= 300,  n_jobs = -1)\n",
        "# clf = SVC(degree= 1, kernel= 'rbf')\n",
        "clf = GradientBoostingClassifier(learning_rate= 0.1, max_depth= 15, min_samples_leaf= 1, min_samples_split= 5, n_estimators= 500)\n",
        "df_Y = df[\"Survived\"]\n",
        "df_X = df.drop([\"Survived\"], axis = 1)\n",
        "df_X = preprocessName(df_X)\n",
        "pipe.fit(df_X, df_Y)\n",
        "df_X = pipe.transform(df_X)\n",
        "clf.fit(df_X, df_Y)\n",
        "# print(df_test.info())\n",
        "df_test = preprocessName(df_test)\n",
        "df_test = pipe.transform(df_test)\n",
        "print(df_test)\n",
        "prediction = clf.predict(df_test)\n",
        "pred_df = pd.DataFrame(prediction, columns=['Survived'])\n",
        "output = pd.concat([output_Id, pred_df], axis=1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 1)\t1.0\n  (0, 3)\t0.3948865804412651\n  (0, 4)\t-0.47454519624983954\n  (0, 5)\t-0.4736736092984604\n  (0, 6)\t-0.49078316061772326\n  (0, 8)\t1.0\n  (0, 11)\t1.0\n  (0, 23)\t1.0\n  (0, 335)\t1.0\n  (1, 2)\t1.0\n  (1, 3)\t1.3555096219574048\n  (1, 4)\t0.4327933656785018\n  (1, 5)\t-0.4736736092984604\n  (1, 6)\t-0.5074788432328381\n  (1, 7)\t1.0\n  (1, 11)\t1.0\n  (1, 24)\t1.0\n  (2, 1)\t1.0\n  (2, 3)\t2.5082572717767726\n  (2, 4)\t-0.47454519624983954\n  (2, 5)\t-0.4736736092984604\n  (2, 6)\t-0.4533668714188957\n  (2, 8)\t1.0\n  (2, 10)\t1.0\n  (2, 23)\t1.0\n  :\t:\n  (415, 3)\t0.7022859537264299\n  (415, 4)\t-0.47454519624983954\n  (415, 5)\t-0.4736736092984604\n  (415, 6)\t-0.5024451714361923\n  (415, 8)\t1.0\n  (415, 11)\t1.0\n  (415, 23)\t1.0\n  (416, 2)\t1.0\n  (416, 3)\t-0.10463740114712752\n  (416, 4)\t-0.47454519624983954\n  (416, 5)\t-0.4736736092984604\n  (416, 6)\t-0.4863374216869257\n  (416, 8)\t1.0\n  (416, 11)\t1.0\n  (416, 23)\t1.0\n  (417, 0)\t1.0\n  (417, 3)\t-0.10463740114712752\n  (417, 4)\t0.4327933656785018\n  (417, 5)\t0.7676298785983874\n  (417, 6)\t-0.19824427701513722\n  (417, 8)\t1.0\n  (417, 11)\t1.0\n  (417, 19)\t1.0\n  (417, 511)\t1.0\n  (417, 892)\t1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Pie_2Wf0Tgm"
      },
      "source": [
        "# Writing to output\n",
        "output.to_csv (r'./export_dataframe.csv', index = False, header=True)"
      ],
      "execution_count": 14,
      "outputs": []
    }
  ]
}